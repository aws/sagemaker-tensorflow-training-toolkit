{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Script Mode to train any TensorFlow script from GitHub in SageMaker\n",
    "\n",
    "In this tutorial, we will show how is simple to train a TensorFlow script in SageMaker using the new Script Mode Tensorflow Container.\n",
    "\n",
    "The example the we choosed is [Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow](https://github.com/sherjilozair/char-rnn-tensorflow) but this same technique can be use to other scripts/repos including [TensorFlow Model Zoo](https://github.com/tensorflow/models) and [TensorFlow benchmark scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seting up the environment\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation [for how to create these](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html). Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the ```sagemaker.get_execution_role()``` with a the appropriate full IAM role arn string(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sherjilozair/char-rnn-tensorflow > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository includes a README.md with an overview of the project, requirements, and basic usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown('char-rnn-tensorflow/README.md'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir sherlock\n",
    "!wget https://sherlock-holm.es/stories/plain-text/cnus.txt --force-directories --output-document=sherlock/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='sherlock', bucket=bucket, key_prefix='datasets/sherlock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Script Mode is still in developement phase. We will have to construct a Estimator to be able to use it with [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker.estimator import Framework\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "class ScriptModeTensorFlow(Framework):\n",
    "    \"\"\"This class is temporary until the final version of Script Mode is released.\n",
    "    \"\"\"\n",
    "    \n",
    "    __framework_name__ = \"tensorflow-scriptmode-beta\"\n",
    "    \n",
    "    create_model = TensorFlow.create_model\n",
    "    \n",
    "    def __init__(self, py_version='py3', **kwargs):\n",
    "        super(ScriptModeTensorFlow, self).__init__(**kwargs)\n",
    "        self.py_version = py_version\n",
    "        self.image_name = None\n",
    "        self.framework_version = '1.10.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use [Local Mode](https://github.com/aws/sagemaker-python-sdk#local-mode) to simulate SageMaker locally before submit training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'num_epochs': 1, \n",
    "                   'data_dir': '/opt/ml/input/data/training',\n",
    "                   'save_dir': '/opt/ml/model'}\n",
    "\n",
    "estimator = ScriptModeTensorFlow(entry_point='train.py',\n",
    "                                 source_dir='char-rnn-tensorflow',\n",
    "                                 train_instance_type='local', \n",
    "                                 train_instance_count=1,\n",
    "                                 hyperparameters=hyperparameters,\n",
    "                                 role=role)\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work\n",
    "\n",
    "The cell above downloaded a Python 3 CPU container locally and used it to simulate SageMaker training. When training starts, the script mode will invoke the following command inside the container:\n",
    "```bash\n",
    "python *entry_point* --hyperparameter1 *hyperparameter value1* --hyperparameter2 *hyperparameter value2* ...\n",
    "```\n",
    "\n",
    "The entrypoint script will be invoke with each hyperparameter as a script argument. The command executed for the example above is:\n",
    "\n",
    "```bash\n",
    "python train.py --num_epochs 1 --data_dir /opt/ml/input/data/training --save_dir /opt/ml/model\n",
    "```\n",
    "\n",
    "**/opt/ml/input/data/training** is the directory inside the container where the training data is downloaded. The data was downloaded in this folder because **training** is the channel name defined in ```estimator.fit({'training': inputs})```. See [training data](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-trainingdata) for more information. \n",
    "\n",
    "**/opt/ml/model** is the directory the model should be saved inside the container. Any data saved in this folder will be saved in the S3 bucket defined for training. See [model data](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-envvariables) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in SageMaker\n",
    "\n",
    "You can change the estimator argument **train_instance_type** to any SageMaker ml instance available for training. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ScriptModeTensorFlow(entry_point='train.py',\n",
    "                                source_dir='char-rnn-tensorflow',\n",
    "                                train_instance_type='ml.c4.xlarge', \n",
    "                                train_instance_count=1,\n",
    "                                hyperparameters=hyperparameters,\n",
    "                                role=role)\n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing additional requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing pip packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script Mode will install your source_dir in the container as a [Python package](https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_modules.py#L100). You can include a [requirements.txt file in the root folder of your source_dir to install any pip dependencies](https://github.com/aws/sagemaker-containers/blob/master/src/sagemaker_containers/_modules.py#L111). You can, for example, install the lastest version of tensorflow in the container:\n",
    "\n",
    "content of requirements.txt\n",
    "```\n",
    "tensorflow==1.11.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing apt-get packages and other dependencies\n",
    "You can define a setup.py file in your source_dir to install other dependencies. The example below will install [TensorFlow for C](https://www.tensorflow.org/install/lang_c) in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir tf_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tf_c/get-tf-c.sh\n",
    "\n",
    "wget -q -t 3 https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.11.0.tar.gz\n",
    "tar -xzvf libtensorflow-cpu-linux-x86_64-1.11.0.tar.gz -C /usr/local\n",
    "\n",
    "ldconfig\n",
    "\n",
    "gcc -I/usr/local/include -L/usr/local/lib hello_tf.c -ltensorflow -o hello_tf\n",
    "cp hello_tf /usr/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tf_c/hello_tf.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <tensorflow/c/c_api.h>\n",
    "\n",
    "int main() {\n",
    "  printf(\"Hello from TensorFlow C library version %s\\n\", TF_Version());\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tf_c/setup.py\n",
    "from distutils.command.build_py import build_py as _build_py\n",
    "from distutils.core import setup\n",
    "import subprocess\n",
    "\n",
    "class build_py(_build_py):\n",
    "    def run(self):\n",
    "        subprocess.check_output(['bash', './get-tf-c.sh'])\n",
    "\n",
    "        super(build_py, self).run()\n",
    "\n",
    "\n",
    "from setuptools import setup\n",
    "setup(packages=[''],\n",
    "      name=\"test\",\n",
    "      version='1.0.0',\n",
    "      cmdclass={'build_py': build_py},\n",
    "      include_package_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tf_c/train_c.py\n",
    "\n",
    "import subprocess\n",
    "\n",
    "message = subprocess.check_output('hello_tf')\n",
    "assert message == b'Hello from TensorFlow C library version 1.11.0\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = ScriptModeTensorFlow(entry_point='train_c.py',\n",
    "                                 source_dir='tf_c',\n",
    "                                 train_instance_type='local', \n",
    "                                 train_instance_count=1,\n",
    "                                 role=role)\n",
    "\n",
    "estimator.fit({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
